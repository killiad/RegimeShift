{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42330857-993e-40b1-92d6-ac8e2b338105",
   "metadata": {},
   "source": [
    "# STEP 1: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39ec507-cbab-43f9-a9ac-c94a3522e94a",
   "metadata": {},
   "source": [
    "1. The data set water_full.csv is the cleaned ltrm data set. This will be the data we begin with. The data set water_data_qfneg.csv is the data set containing temporal information.\n",
    "2. We want to first ensure that there is the same number of data points in each season. This allows us to meaningfully view the data set as a time series.\n",
    "3. To do this, run Season_Interpolation.py. Note that data for 2003 and fall 2002 is missing. To remedy this, we reuse the data from 2002 for 2003, and reuse fall 2001 for 2002. For Pool 13, winter 1999, there is also high missingness in the data. Likewise, we use the data from winter 1998 to interpolate. Additionally, winter 1996 is missing. In our final analysis of the data, we do not make any conclusions about the ecology of the river during these times, so this interpolation is okay. The interpolation is important since it allows us to look at a larger time frame.\n",
    "4. Season_Interpolation.py will create a new data set called Fix_Seasons_PoolName_StartYear_EndYear_EntriesPerSeason.csv. (For example, Fix_Seasons_Pool13_1995_2019_110.) The new data set also has the time of each entry, and is ordered temporally. For Pool 13 we have 110 entries per season and for Onalaska we have 97 entries per season.\n",
    "5. Next, since we are investigating regime shifts, outliers and data on the extremes do not matter. We are concerned with finding when the median data changes. To address this, we create a new data set that only contains the middle 50% of each variable.\n",
    "6. To create aforementioned data set, run Middle_50.py. This will create a new data set called Middle_50_PoolName_StartYear_EndYear_EntriesPerSeason_Variable.csv. (For example, Middle_50_Pool13_1995_2019_54_TP.csv.) We need a new data set for each variable since the middle 50% of each variable may not match up temporally. For Pool 13 we had 54 entries per season and for Onalaska we had 48 entries per season.\n",
    "7. After completing all these steps for each pool, we are now ready to run the period prediction algorithm and the change point detection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e56a6f-db8c-48d4-95c6-07e25f2df6fa",
   "metadata": {},
   "source": [
    "# STEP 2: Change Point Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc23eff-b22d-4dbd-93c5-166a98db5396",
   "metadata": {},
   "source": [
    "1. Next, we want to run change point detection algorithms on the data sets created in Step 1. If multiple change points line us with the cycle disruptions found in Step 2, then we have a stronger indication of a regime shift.\n",
    "2. To do this, run CPD.py. This will run an algorithm that will answer the question, \"Assuming a break point exists, what is the most likely breakpoint?\" If the algorithm claims there is a break point very near the beginning or near the end of the time series, it can likely be disregarded. The script will create graphs for each variable and their respective change points.\n",
    "3. Note that the graphs created are not the literal time series. Instead, the algorithm creates a new time series capturing the geometric and topological properties of the original time series, then we run a standard change point detection algorithm on this new time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b3c0e-e279-450d-a122-1e7a0913b430",
   "metadata": {},
   "source": [
    "# STEP 3: T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca20886-0257-42b8-b6c0-f62ae504fb72",
   "metadata": {},
   "source": [
    "1. Finally, we will perform t-tests to deduce the significance of the breakpoint.\n",
    "2. To do this, run T_Test,py. The output will be a csv file with the p-values of each season for samples from before and after the breakpoint. We run each t-test 1000 times and take the average p-value. We consider p-values below .05 to be significant. We use a sample size of 60.\n",
    "3. If a collection of variables have a disruption in periodic behavior around the same time, have a change point at around the same time, and passes the t-test, then we claim that there was a regime shift and that those variables drove the regime shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c438466-e278-41cc-aefb-39f10d9eb659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
